import pandas as pd 
import numpy as np
import random as rd 
import matplotlib.pyplot as plt

data = pd.read_csv("arxiv_dataset.csv") # replace with actual file name
data.drop(["id", "submitter", "comments", "journal-ref", "doi", "versions"], axis=1, inplace=True)

# vectorize dataset
# idk how data sets work so lets just say categories is a 1 by n array 
# with all the categories for all n research papers
category_keys = sorted(set(categories.tolist()))
d = len(category_keys)
one_hot_cat = []
for category in categories:
    encoding = [0] * d
    encoding[category_keys.index(category)] = 1
    one_hot_cat.append(encoding)


K = 150 
Centroids = (data.sample(n=K))

diff = 1
j = 0 

while diff != 0:
    data_copy = data
    i = 1
    for index_1, row_1 in Centroids.iterrows():
        ED = []
        for index_2, row_2 in data_copy.iterrows():
            # do in numpy
            d1 = (row_1["authors"] - row_2["authors"])**2
            d2 = (row_1["title"] - row_2["title"])**2
            d3 = (row_1["abstract"] - row_2["abstract"])**2
            d4 = (row_1["categories"] - row_2["categories"])**2
            d = np.sqrt(d1+d2+d3+d4)
            ED.append(d)
        data[i] = ED
        i += 1
    
    C = []
    for index, row in data.iterrows():
        min_dist = row[1]
        pos = 1
        for i in range(K):
            if row[i+1] < min_dist:
                min_dist = row[i+1]
                pos = i + 1
        C.append(pos)
    data["Cluster"] = C
    Centroids_new = data.groupby(["Cluster"]).mean()[["authors","title","abstract","categories"]]
    if j == 0:
        diff = 1
        j += 1
    else:
        diff = ((Centroids_new["authors"] - Centroids["authors"]).sum() +
                (Centroids_new["title"] - Centroids["title"]).sum() + 
                (Centroids_new["abstract"] - Centroids["abstract"]).sum() + 
                (Centroids_new["categories"] - Centroids["categories"]).sum())
    Centroids = data.groupby(["Cluster"]).mean()[["authors","title","abstract","categories"]]
